### **1. Introducci√≥n**

En este tutorial, aprender√°s c√≥mo usar **Semantic Kernel** para integrar modelos de lenguaje avanzados y construir un servicio REST que resuma texto. Utilizaremos **Ollama** como motor local de modelos de lenguaje, lo que nos permitir√° evitar el uso de servicios en la nube en esta fase de desarrollo.

El objetivo principal es configurar un entorno de trabajo funcional en C# que permita a los desarrolladores:

1. Conectar un modelo de lenguaje local (_llama3.2_).
2. Crear un kernel para manejar habilidades personalizadas.
3. Exponer la funcionalidad como un endpoint REST en una API ASP.NET Core.

Al finalizar, tendr√°s un servicio de API que podr√° recibir texto como entrada y devolver un resumen en una sola oraci√≥n. Esto no solo te ayudar√° a entender c√≥mo usar Semantic Kernel, sino que tambi√©n te dar√° una base s√≥lida para construir aplicaciones pr√°cticas basadas en IA generativa.

### **2. Introducci√≥n a Semantic Kernel**

#### **2.1. ¬øQu√© es Semantic Kernel?**

**Semantic Kernel** es un framework desarrollado por Microsoft para integrar modelos de lenguaje avanzados en aplicaciones. Permite a los desarrolladores conectar diferentes motores de IA generativa, definir habilidades personalizadas mediante prompts y construir flujos complejos de manera program√°tica.

En este tutorial, usaremos Semantic Kernel junto con **Ollama**, un motor local de modelos de lenguaje, para crear y gestionar una habilidad de generaci√≥n de texto que resuma contenido.

#### **2.2. Componentes Claves**

1. **Kernel**:  
    El n√∫cleo del framework que conecta el modelo de IA con la l√≥gica de la aplicaci√≥n. En este caso, lo configuramos para usar Ollama como motor de generaci√≥n de texto.
2. **Skills** (_Habilidades_):  
    Son capacidades espec√≠ficas que se pueden programar en el kernel. Aqu√≠ definimos una habilidad b√°sica para resumir texto, utilizando prompts personalizados.
3. **Text Generation Service**:  
    Una abstracci√≥n que maneja las interacciones con el modelo de lenguaje. Se utiliza para enviar el texto de entrada y obtener la respuesta generada por el modelo.
4. **Ollama**:  
    Una soluci√≥n local para ejecutar modelos de lenguaje, que elimina la necesidad de servicios en la nube y facilita el desarrollo en entornos locales. En el c√≥digo, configuramos **Ollama** para usar el modelo `llama3.2`.

### **3. Desarrollo del Ejemplo**

En esta secci√≥n, construiremos un API REST que utiliza **Semantic Kernel** y el modelo de lenguaje **llama3.2** de **Ollama** para resumir texto en una sola oraci√≥n. El objetivo es entender c√≥mo configurar el entorno y crear una habilidad b√°sica que pueda ser utilizada desde cualquier aplicaci√≥n a trav√©s de un endpoint.

#### **3.1. Configuraci√≥n con Aspire**

Antes de entrar en los detalles del API, configuramos el entorno utilizando **Aspire**. Este framework facilita la construcci√≥n de aplicaciones distribuidas, simplificando la gesti√≥n de dependencias y servicios.

Lo que he hecho para simplificar la configuraci√≥n, es utilizar Visual Studio para crear la soluci√≥n ejemplo de Aspire con .NET 9:

![Image description](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/9av06ysmd1bwoiyyj7is.png)

Esta plantilla, tambi√©n incluye un proyecto de Blazor, en este tutorial no lo utilizaremos, pero al finalizar, puedes utilizar ese proyecto para consumir los endpoints realizados y ya tener una aplicaci√≥n funcional.

El c√≥digo de Aspire tiene los siguientes prop√≥sitos:

- **Configurar Ollama:** Define el modelo `llama3.2` como el motor de lenguaje. Esto nos permite trabajar con un modelo local, eliminando la necesidad de infraestructura compleja en desarrollo.
- **Modularidad:** Cada proyecto (como `SemanticKernelLearning01_ApiService`) se configura como un m√≥dulo independiente, permitiendo una estructura clara y extensible.

**Nota:** Usar Ollama local es ideal para pruebas y desarrollo, ya que no requiere configurar una infraestructura en la nube. Sin embargo, en producci√≥n puedes cambiar a OpenAI o Azure OpenAI sin modificar el c√≥digo, aprovechando la flexibilidad de Semantic Kernel.

#### **C√≥digo de Aspire:**

Primero necesitamos los siguientes paquetes:

```xml
  <ItemGroup>
    <PackageReference Include="Aspire.Hosting.AppHost" Version="9.0.0" />
    <PackageReference Include="CommunityToolkit.Aspire.Hosting.Ollama" Version="9.1.0" />
  </ItemGroup>
```

```csharp
var builder = DistributedApplication.CreateBuilder(args);

var ollama =
    builder
        .AddOllama("ollama")// <-- Utilizar√° docker para usar ollama y sus modelos 
        .WithDataVolume()   // <-- Volumen de Docker para persistir modelos descargados
        .WithOpenWebUI();   // <-- UI Estilo ChatGPT

// Descarga el modelo llama3.2 con nombre "llama"
var llamaModel = ollama.AddModel("llama", "llama3.2");

// Nuestra API depende de Ollama, por lo que se referencia y espera a que est√© listo
builder.AddProject<Projects.SemanticKernelLearning01_ApiService>("apiservice")
    .WithReference(llamaModel)
    .WaitFor(llamaModel);

builder.Build().Run();
```

Aqu√≠ configuramos Ollama como motor de generaci√≥n de texto y vinculamos el modelo `llama3.2`. Tambi√©n iniciamos el servicio API como un m√≥dulo dentro del proyecto.

#### **3.2. Configuraci√≥n del API REST**

En el siguiente bloque de c√≥digo, configuramos un API REST utilizando **ASP.NET Core** y **Semantic Kernel**. Aqu√≠ se define un endpoint que acepta texto como entrada y devuelve su resumen generado por el modelo de lenguaje.

**Puntos clave del c√≥digo:**

1. **Kernel y Ollama:** Se inicializa el kernel de Semantic Kernel y se conecta con Ollama usando la configuraci√≥n definida en Aspire.
2. **Habilidad de Resumen:** La l√≥gica para resumir texto se encapsula en un prompt que el modelo interpreta para generar respuestas.
3. **Exposici√≥n del Endpoint:** Se define un endpoint `/api/summarizer` que recibe un objeto JSON con el texto a resumir y devuelve el resultado.

#### **C√≥digo del API REST:**

Paquetes necesarios:

```xml
  <ItemGroup>
    <PackageReference Include="Microsoft.AspNetCore.OpenApi" Version="9.0.0" />
    <PackageReference Include="Microsoft.SemanticKernel" Version="1.33.0" />
    <PackageReference Include="Microsoft.SemanticKernel.Connectors.Ollama" Version="1.33.0-alpha" />
  </ItemGroup>
```

**Program.cs**

```csharp
var builder = WebApplication.CreateBuilder(args);

builder.AddServiceDefaults();
builder.Services.AddProblemDetails();
builder.Services.AddOpenApi();

var kernel = builder.Services.AddKernel();

var (endpoint, modelId) = GetOllamaConnectionString();

#pragma warning disable SKEXP0070
kernel.AddOllamaTextGeneration(modelId, endpoint); // Est√° en alpha, puede cambiar.
#pragma warning restore SKEXP0070

var app = builder.Build();

app.UseExceptionHandler();

if (app.Environment.IsDevelopment())
{
    app.MapOpenApi();
}

app.MapDefaultEndpoints();

app.MapPost("/api/summarizer", async (
    TextCompletionRequest request,
    ITextGenerationService textGenerationService) =>
{
    var prompt = $"""
                 Summarize the following text in one sentence:  

                 {request.Text}
                 """;

    var response = await textGenerationService.GetTextContentsAsync(prompt);

    return response;
});

app.Run();

```

#### **3.3. Explicaci√≥n General del Flujo**

1. **Creaci√≥n del Kernel:**  
    Se configura el kernel para usar Ollama como motor de generaci√≥n de texto con el modelo `llama3.2`.
2. **Definici√≥n del Endpoint:**  
    El endpoint `/api/summarizer` recibe un JSON con una propiedad `Text`.
3. **Generaci√≥n del Resumen:**  
    El texto recibido se env√≠a al modelo junto con un prompt que instruye al modelo para resumirlo en una oraci√≥n.
4. **Devoluci√≥n del Resultado:**  
    El resumen generado se devuelve como respuesta al cliente que llam√≥ al API.

C√≥digo restante:

```csharp
(Uri endpoint, string modelId) GetOllamaConnectionString()
{
    // Este ConnectionString es establecida por Aspire
    var connectionString = builder.Configuration.GetConnectionString("llama");

    var connectionBuilder = new DbConnectionStringBuilder
    {
        ConnectionString = connectionString
    };

    Uri endpoint = new Uri(connectionBuilder["Endpoint"].ToString());
    string modelId = connectionBuilder["Model"].ToString();

    return (endpoint, modelId);
}

// Simple DTO
public record TextCompletionRequest(string Text);
```

> Nota üí°: Recuerda que siempre puedes descargar el c√≥digo desde desde este [Repositorio](https://github.com/isaacOjeda/DevToPosts/tree/main/SemanticKernelSeries/SemanticKernelLearning01)
> 

#### **3.4 Probando la soluci√≥n** 

Si corremos el proyecto de Aspire, autom√°ticamente orquestar√° lo necesario para que la API pueda comunicarse con ollama:


![Image description](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/tv7ykzjwjcw13l0q4l7h.png)

Su primera ejecuci√≥n ser√° lenta, ya que tendr√° que descargar el modelo `llama3.2`.

Existen muchos modelos que podemos ejecutar, tanto para Text Generation y para Embeddings (revisado en pr√≥xmos post), puedes revisar m√°s aqu√≠: [Ollama](https://ollama.com/).

Probemos el endpoint (utilizando Visual Studio y un archivo .http):

```
@host = https://localhost:7384

### Text Generation
POST {{host}}/api/summarizer
Content-Type: application/json

{
    "text": "Mariana found an ancient book in her grandfather‚Äôs library, with a bookmark pointing to a page that read, ‚ÄúRecite these words and your destiny will change.‚Äù Intrigued, she read it out loud, and in an instant, she found herself in a bustling market in a medieval town. \rNo one seemed surprised by her modern clothing; in fact, one merchant greeted her as if he knew her. As she searched for answers, an old man explained that she was the heir to a lost legacy and had to make a choice: stay and lead a kingdom on the brink of chaos, or return to her everyday life. \rWith the book in her hands, Mariana took a deep breath and closed her eyes, choosing the challenge she had secretly always wanted."
}

```

Respuesta:

```json
[
¬†¬†{
¬†¬†¬†¬†"text":¬†"Mariana¬†discovers¬†an¬†ancient¬†book¬†that¬†transports¬†her¬†to¬†a¬†medieval¬†town,¬†where¬†she¬†learns¬†she¬†is¬†the¬†heir¬†to¬†a¬†lost¬†legacy¬†and¬†must¬†make¬†a¬†choice¬†between¬†returning¬†to¬†her¬†ordinary¬†life¬†or¬†leading¬†a¬†kingdom¬†on¬†the¬†brink¬†of¬†chaos.",
¬†¬†¬†¬†"modelId":¬†"llama3.2"
¬†¬†}
]
```

La ejecuci√≥n de modelos con ollama claro que suele ser m√°s lento, para acelerar su ejecuci√≥n debemos de contar con una GPU y de preferencia Nvidia. 

Para operaciones sencillas, me ha funcionado bien y como vemos, la respuesta ha funcionado, todo ejecutandose en nuestra computadora.
### **4. Conclusi√≥n**

En este tutorial, exploramos los fundamentos de **Semantic Kernel** y c√≥mo integrarlo con **Ollama** para construir un servicio funcional capaz de generar res√∫menes de texto. A trav√©s de este ejercicio:

- Aprendiste a configurar un entorno b√°sico utilizando **Aspire**, simplificando la administraci√≥n de servicios distribuidos.
- Descubriste c√≥mo conectar Semantic Kernel con un motor de lenguaje local, como **llama3.2** de Ollama, para evitar complicaciones de infraestructura en desarrollo.
- Implementaste un API REST con un endpoint pr√°ctico que utiliza generaci√≥n de texto como una habilidad central.

Este ejercicio muestra lo vers√°til que puede ser Semantic Kernel para crear aplicaciones inteligentes que aprovechan los modelos de lenguaje. Adem√°s, la flexibilidad de la arquitectura permite cambiar f√°cilmente entre diferentes proveedores de modelos, como OpenAI o Azure, sin necesidad de modificar el c√≥digo base.

Este tutorial es solo el inicio. A partir de aqu√≠, puedes explorar y agregar nuevas habilidades, integrar bases de datos vectoriales para contextualizar las respuestas o expandir el API con capacidades adicionales.

### **5. Pr√≥ximos Pasos**

Ahora que ya tienes una base s√≥lida para trabajar con **Semantic Kernel** y **Ollama**, considera avanzar con los siguientes temas para expandir tus conocimientos:

1. **Ampliar tus habilidades en Semantic Kernel:**
    - Aprende a crear habilidades m√°s complejas con m√∫ltiples pasos y dependencias.
    - Explora c√≥mo usar conectores para integrar datos externos, como archivos, APIs, o bases de datos.
2. **Incorporar contexto mediante bases de datos vectoriales:**
    - Experimenta con herramientas como Qdrant o Pinecone para agregar contexto a las respuestas basadas en vectores.
    - Usa embeddings para conectar preguntas con datos relevantes en tiempo real.
3. **Migrar a un entorno de producci√≥n:**
    - Configura la misma API para usar OpenAI o Azure OpenAI como motores de generaci√≥n de texto.
    - Aprende a manejar credenciales y seguridad en aplicaciones en producci√≥n.
4. **Construir una interfaz gr√°fica:**
    - Usa **Blazor** para crear una interfaz interactiva donde los usuarios puedan interactuar con tus habilidades de Semantic Kernel.
5. **Desarrollar tutoriales m√°s avanzados:**
    - Ense√±a a otros c√≥mo resolver problemas reales, como an√°lisis de sentimientos, clasificaci√≥n de texto o generaci√≥n de contenido adaptado al contexto.
